python tools/dataset_patch_split.py --dataset-type "vaihingen" \
--img-dir "/mnt/d/rssegmentation/data/vaihingen/ISPRS_semantic_labeling_Vaihingen/top" \
--mask-dir "/mnt/d/rssegmentation/data/vaihingen/ISPRS_semantic_labeling_Vaihingen_ground_truth_COMPLETE" \
--output-img-dir "/mnt/d/rssegmentation/data/vaihingen/train/images_1024" \
--output-mask-dir "/mnt/d/rssegmentation/data/vaihingen/train/masks_1024" \
--split-size 1024 --stride 512 --mode "train"

python tools/dataset_patch_split.py --dataset-type "vaihingen" \
--img-dir "/mnt/d/rssegmentation/data/vaihingen/ISPRS_semantic_labeling_Vaihingen/top" \
--mask-dir "/mnt/d/rssegmentation/data/vaihingen/ISPRS_semantic_labeling_Vaihingen_ground_truth_COMPLETE" \
--output-img-dir "/mnt/d/rssegmentation/data/vaihingen/test/images_1024" \
--output-mask-dir "/mnt/d/rssegmentation/data/vaihingen/test/masks_1024_RGB" \
--split-size 1024 --stride 1024 --mode "test"

python tools/dataset_patch_split.py --dataset-type "vaihingen" \
--img-dir "/mnt/d/rssegmentation/data/vaihingen/ISPRS_semantic_labeling_Vaihingen/top" \
--mask-dir "/mnt/d/rssegmentation/data/vaihingen/ISPRS_semantic_labeling_Vaihingen_ground_truth_eroded_COMPLETE" \
--output-img-dir "/mnt/d/rssegmentation/data/vaihingen/test/images_1024" \
--output-mask-dir "/mnt/d/rssegmentation/data/vaihingen/test/masks_1024" \
--split-size 1024 --stride 1024 --mode "test"



python tools/dataset_patch_split.py --dataset-type "potsdam" \
--img-dir "/mnt/d/rssegmentation/data/potsdam/2_Ortho_RGB" \
--mask-dir "/mnt/d/rssegmentation/data/potsdam/5_Labels_all" \
--output-img-dir "/mnt/d/rssegmentation/data/potsdam/train/images_1024" \
--output-mask-dir "/mnt/d/rssegmentation/data/potsdam/train/masks_1024" \
--split-size 1024 --stride 512 --mode "train"

python tools/dataset_patch_split.py --dataset-type "potsdam" \
--img-dir "/mnt/d/rssegmentation/data/potsdam/2_Ortho_RGB" \
--mask-dir "/mnt/d/rssegmentation/data/potsdam/5_Labels_all_noBoundary" \
--output-img-dir "/mnt/d/rssegmentation/data/potsdam/test/images_1024" \
--output-mask-dir "/mnt/d/rssegmentation/data/potsdam/test/masks_1024" \
--split-size 1024 --stride 1024 --mode "test"

python tools/dataset_patch_split.py --dataset-type "potsdam" \
--img-dir "/mnt/d/rssegmentation/data/potsdam/2_Ortho_RGB" \
--mask-dir "/mnt/d/rssegmentation/data/potsdam/5_Labels_all" \
--output-img-dir "/mnt/d/rssegmentation/data/potsdam/test/images_1024" \
--output-mask-dir "/mnt/d/rssegmentation/data/potsdam/test/masks_1024_RGB" \
--split-size 1024 --stride 1024 --mode "test"









python test.py \
-c "configs/logcan.py" \
--ckpt "work_dirs/LoGCAN_ResNet50_Loveda/epoch=47.ckpt" \

python test3.py -c "configs/logcanplus.py" --ckpt "work_dirs/LoGCAN_ResNet50_Loveda/epoch=45.ckpt" 



python test3.py \
-c "configs/logcanplus.py" \
--ckpt "work_dirs/LoGCAN_ResNet50_vaihingen/epoch=47.ckpt" 

python train.py -c "configs/logcanplus.py

python online_test.py \
-c "configs/logcanplus.py" \
--ckpt "work_dirs/LoGCAN_ResNet50_Loveda/epoch=45.ckpt" \

python tools/flops_params_count.py -c configs/vaihingen/logcanplus.py           --> produces architecture

python train.py -c configs/loveda/logcanplus.py

	

python test3.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=129.ckpt 

pip install torchmetrics==0.11.4 pytorch-lightning==2.0.6 scikit-image==0.21.0 catalyst==20.9 albumentations==1.3.1 ttach==0.0.3 einops==0.6.1 timm==0.6.7 addict==2.4.0 soundfile==0.12.1 prettytable==3.8.0 grad-cam==1.5.4

python train.py -c configs/potsdam/logcanplus.py


python online_test.py -c configs/loveda/logcanplus.py --ckpt work_dirs/logcanplus_loveda/epoch=40.ckpt              run this to

python online2.py -c configs/loveda/logcanplus.py --ckpt work_dirs/logcanplus_loveda/epoch=40.ckpt 

python tools/latency_count.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=129.ckpt 


python tools/latency_count.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=129.ckpt 



python tools/cam2.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=129.ckpt --tar_layer "model.net.seghead.catconv2[-2]" --tar_category 1


  python tools/tsne2.py   -c configs/vaihingen/logcanplus.py   --ckpt work_dirs/logcanplus_vaihingen/epoch=129.ckpt 





e:
cd rssegmentation


python test4.py -c "configs/loveda/logcanplus.py" --ckpt "work_dirs/logcanplus_loveda/epoch=40.ckpt" 

python test4.py -c "configs/vaihingen/logcanplus.py" --ckpt "work_dirs/logcanplus_vaihingen/epoch=129.ckpt" 



---------------


python test3.py -c configs/loveda/logcanplus.py --ckpt work_dirs/logcanplus_loveda/epoch=40.ckpt 				run this



python online_test.py -c configs/loveda/logcanplus.py --ckpt work_dirs/logcanplus_loveda/epoch=40.ckpt              run this to
	
----------------

Using **RepViT-M2.3** for your **remote sensing segmentation model** has several advantages:

1. **High Efficiency with Low Latency**  
   - RepViT is designed as a lightweight CNN optimized for mobile and edge devices.
   - **RepViT-M2.3 achieves 83.7% accuracy with only 2.3 ms latency on an iPhone 12**, making it highly efficient.

2. **Optimized for Convolutional Operations**  
   - Unlike traditional Vision Transformers (ViTs), which struggle with high-resolution inputs, RepViT retains CNN efficiency while integrating ViT-inspired design improvements.

3. **Improved Segmentation Performance**  
   - RepViT-M2.3 has been evaluated for **semantic segmentation on ADE20K**, achieving **higher mIoU (46.1%) compared to EfficientFormerV2-L (45.2%)** while being nearly **twice as fast**.

4. **Strong Downstream Task Performance**  
   - It has demonstrated superior transferability for object detection, instance segmentation, and semantic segmentation.
   - The model **outperforms EfficientFormerV2 on COCO and ADE20K segmentation tasks**.

5. **Faster Training and Inference**  
   - Compared to ViTs, which require **more memory and computation**, RepViT uses **structural re-parameterization**, reducing inference time without sacrificing accuracy.

6. **Scalability**  
   - The **RepViT family includes multiple variants**, and M2.3 is the largest, meaning it provides **higher accuracy with controlled latency**.

Since **remote sensing segmentation models** often deal with **high-resolution satellite imagery**, **RepViT-M2.3** could offer an **excellent balance of speed and accuracy** while avoiding **ViT-related latency bottlenecks**. Would you like help with specific **implementation details**?









python tools/flops_params_count.py -c configs/vaihingen/logcanplus.py 

got some model kinda thing


python tools/latency_count.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=129.ckpt 

goy some reading 


