
## ğŸ“ MACs Calculation

Multiplyâ€“Accumulate Operations (MACs) are calculated as:

```
MACs = 2 Ã— Kernel Size Ã— Input Channels Ã— Output Channels Ã— Output Width Ã— Output Height
```

Example for a `Conv2D` layer:

- Input Channels = 3 (RGB)
- Output Channels = 40
- Kernel Size = 3Ã—3 = 9
- Stride = 2
- Padding = 1
- Input Size = 224Ã—224

You can calculate MACs using the above formula after deriving the output feature map dimensions.

---

## ğŸ† Which is Better for Satellite Image Segmentation?

- âœ… If **accuracy** is top priority: use ResNet-based DeepLabV3+, U-Net, etc.
- âš¡ If **real-time segmentation** is needed (e.g., drones): use lightweight models like **RepViT**.

---

## âš™ï¸ RepViTBlock Components

### 1. **Token Mixer**
- Responsible for spatial feature extraction.
- Uses:
  - `RepVGGDW`: depthwise convolution
  - `SEModule`: adds lightweight attention

### 2. **RepVGGDW**
- Depthwise conv applied per input channel.
- Efficient with reduced computational complexity.
- Derived from RepVGG architecture for faster inference.

### 3. **SEModule (Squeeze-and-Excitation)**
- Provides channel-wise attention.
- Architecture:
  - `fc1` â†’ `ReLU` â†’ `fc2` â†’ `Sigmoid`
- Enhances important features while suppressing noise.

### 4. **Channel Mixer**
- Applies 1Ã—1 convolutions for channel-wise mixing.
- Implemented as a residual block with:
  - Two `Conv2D_BN` layers
  - `GELU` activation

### 5. **GELU Activation**
Smoother than ReLU, used in transformers and modern conv nets.

```
GELU(x) = 0.5 * x * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715x^3)))
```

---

## ğŸ” RepViTBlock Layer Comparison

| Property        | Block (2)            | Block (53)            |
|----------------|----------------------|------------------------|
| Params         | 26.48K               | 1.851M                |
| MACs           | 433.848M             | 421.438M              |
| Channel Size   | 80                   | 640                   |
| SE Module      | âŒ No                | âœ… Yes                |

- **Block 2**: Lightweight and early-stage processing
- **Block 53**: High-capacity, deeper-layer block with attention

---

## ğŸ“ˆ Functional Purpose in Segmentation

- Early layers (e.g., Block 2):
  - Extract low-level textures and edges
  - Lightweight and fast

- Deeper layers (e.g., Block 53):
  - Capture global context and semantics
  - Use SE attention for enhanced channel representation

âœ… Alternating light-heavy block structure improves overall balance between **efficiency** and **feature expressiveness**

---

## ğŸ“’ Folder Structure

<details>
<summary>Prepare the following folders to organize this repo:</summary>

```
rssegmentation
â”œâ”€â”€ rsseg
â”œâ”€â”€ tools
â”œâ”€â”€ work_dirs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ LoveDA
â”‚   â”‚   â”œâ”€â”€ Train/Urban/images_png, masks_png
â”‚   â”‚   â”œâ”€â”€ Train/Rural/images_png, masks_png
â”‚   â”‚   â”œâ”€â”€ Val
â”‚   â”‚   â”œâ”€â”€ Test
â”‚   â”œâ”€â”€ vaihingen
â”‚   â”‚   â”œâ”€â”€ ISPRS_semantic_labeling_Vaihingen
â”‚   â”‚   â”œâ”€â”€ ISPRS_semantic_labeling_Vaihingen_ground_truth_COMPLETE
â”‚   â”‚   â”œâ”€â”€ ISPRS_semantic_labeling_Vaihingen_ground_truth_eroded_COMPLETE
â”‚   â”‚   â”œâ”€â”€ train
â”‚   â”‚   â”œâ”€â”€ test
â”‚   â”œâ”€â”€ potsdam
â”‚   â”‚   â”œâ”€â”€ 2_Ortho_RGB
â”‚   â”‚   â”œâ”€â”€ 5_Labels_all
â”‚   â”‚   â”œâ”€â”€ 5_Labels_all_noBoundary
â”‚   â”‚   â”œâ”€â”€ train
â”‚   â”‚   â”œâ”€â”€ test
```

</details>

---

## ğŸ” Preparation

### Environment

```bash
conda create -n rsseg python=3.9
conda activate rsseg
conda install pytorch==2.0.0 torchvision==0.15.0 torchaudio==2.0.0 pytorch-cuda=11.7 -c pytorch -c nvidia
pip install -r requirements.txt
```

### Data Preprocess

```bash
bash tools/vaihingen_preprocess.sh 
bash tools/potsdam_preprocess.sh 
```

ğŸ“¦ Preprocessed datasets available:
- [Vaihingen](https://pan.baidu.com/s/18zLMK8-gleYFyyXl-OWHrg)
- [Potsdam](https://pan.baidu.com/s/1qunEBhLH_GhqsnU6ZVK6TQ)

---

## ğŸ“š Use Example

### 1ï¸âƒ£ Training

```bash
python train.py -c configs/vaihingen/logcanplus.py
```

### 2ï¸âƒ£ Testing

#### Vaihingen and Potsdam
```bash
python test.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=45.ckpt
```

#### LoveDA (for online evaluation)

```bash
python online_test.py -c configs/loveda/logcanplus.py --ckpt work_dirs/logcanplus_loveda/epoch=45.ckpt
```

---

## ğŸ› ï¸ Tools

### Param and FLOPs

```bash
python tools/flops_params_count.py -c configs/vaihingen/logcanplus.py
```

### Latency

```bash
python tools/latency_count.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=45.ckpt
```

### Throughput

```bash
python tools/throughput_count.py -c configs/vaihingen/logcanplus.py
```

### Class Activation Map

```bash
python tools/cam.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=45.ckpt --tar_layer "model.net.seghead.catconv2[-2]" --tar_category 1
```

### TSNE Map

```bash
python tools/tsne.py -c configs/vaihingen/logcanplus.py --ckpt work_dirs/logcanplus_vaihingen/epoch=45.ckpt
```

---

